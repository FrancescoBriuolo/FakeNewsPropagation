Best params for FNN: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 16, 'early_stopping': True, 'hidden_layer_sizes': [50], 'learning_rate': 'adaptive', 'max_iter': 2000, 'n_iter_no_change': 15, 'solver': 'adam'}
